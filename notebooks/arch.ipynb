{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some variables:\n",
    "\n",
    "* $B$: batch size,\n",
    "* $n_L$: number of layers per \"node\",\n",
    "* $N$: total number of model layers,\n",
    "* $S_\\text{kv}$: Maximum size of the KV-cache per prompt per layer.\n",
    "\n",
    "Assume network latency is negligible.\n",
    "\n",
    "We define $t(B,n)$ as the time to push a batch of size $B$ through $n$ layers. $t(B, n) \\approx n \\cdot t(B, 1)$.\n",
    "\n",
    "Throughput would be\n",
    "$$T = \\frac{B}{t(B, n_L)} =\\frac{B}{n_L \\cdot t(B)}$$\n",
    "\n",
    "Latency of a token going through all layers is\n",
    "$$l = \\frac{N}{n_L} \\cdot t(B, n_L) = N \\cdot t(B)$$\n",
    "\n",
    "Therefore, the number of active prompts needed to keep the pipeline full is\n",
    "$$T \\cdot l = \\frac{B}{n_L \\cdot t(B)} \\cdot N \\cdot t(B) = B\\cdot \\frac{N}{n_L}\\quad\\text{(Little's law)}$$ \n",
    "\n",
    "Amount of memory necessary for storing KV-cache on each node is\n",
    "$$M_\\text{kv} = B \\cdot \\frac{N}{n_L} \\cdot (n_L \\cdot S_\\text{kv}) = B \\cdot N \\cdot S_\\text{kv}$$\n",
    "\n",
    "Therefore, the memory requirement for each node is only dependent on batch size and number of model layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is maximize $T$ subject to $M_\\text{kv} \\le \\text{node mem}$.\n",
    "\n",
    "$$B_{opt} = \\underset{B}{\\mathrm{argmax}} \\left\\{ \\frac{B}{n_L \\cdot t(B)} \\right\\}, \\quad \\text{s.t. }\\,\\, B \\le \\frac{\\text{node mem}}{N\\cdot S_\\text{kv}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some conlusions \n",
    "\n",
    "* For Llama2-70B ($N=80$, $S_\\text{kv}=16\\,\\text{MB}$) on a node with $100\\,\\text{GB}$ memory for the KV-cache, $B \\le 80$.\n",
    "\n",
    "* Based on imperical data, $\\frac{B}{t(B)}$ always increases with $B$, so $$B_{opt} = \\frac{\\text{node mem}}{N\\cdot S_\\text{kv}}$$\n",
    "\n",
    "* Given a fixed number of nodes, total throughput is not dependent on the number of layers on a single node. For example, if we have $80$ nodes and $n_L = 2$, for one instance of the model we use 40 nodes with half the throughput of $n_L = 1$, but we can run two model instances concurrently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
